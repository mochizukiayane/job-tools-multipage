import streamlit as st
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import base64

st.set_page_config(page_title="ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼")

st.title("ğŸ–¼ï¸ ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ€ãƒ¼")

url = st.text_input("ç”»åƒã‚’å–å¾—ã—ãŸã„Webãƒšãƒ¼ã‚¸ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if url:
    try:
        res = requests.get(url)
        soup = BeautifulSoup(res.text, "lxml")
        images = soup.find_all("img")

        image_urls = []
        for img in images:
            src = img.get("src")
            if src:
                full_url = urljoin(url, src)
                image_urls.append(full_url)

        st.write(f"ç”»åƒæ•°ï¼š{len(image_urls)}æš")

        for i, img_url in enumerate(image_urls):
            try:
                img_data = requests.get(img_url).content
                b64 = base64.b64encode(img_data).decode()
                href = f'<a href="data:image/jpeg;base64,{b64}" download="image_{i}.jpg">ğŸ“¥ ç”»åƒ{i+1} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰</a>'
                st.image(img_url, width=200)
                st.markdown(href, unsafe_allow_html=True)
                st.markdown("---")
            except:
                st.warning(f"ç”»åƒ{i+1}ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")

    except Exception as e:
        st.error("ç”»åƒã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.error(e)
