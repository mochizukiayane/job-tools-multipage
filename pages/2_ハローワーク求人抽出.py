import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
import random

st.set_page_config(page_title="ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ã‚¯æ±‚äººæŠ½å‡ºãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ“‹ ãƒãƒ­ãƒ¼ãƒ¯ãƒ¼ã‚¯æ±‚äººæŠ½å‡ºãƒ„ãƒ¼ãƒ«")
st.markdown("URLã‚’æœ€å¤§5ä»¶ã¾ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

with st.form("job_form"):
    urls_input_1 = st.text_input("ğŸ”— æ±‚äººURL 1")
    urls_input_2 = st.text_input("ğŸ”— æ±‚äººURL 2")
    urls_input_3 = st.text_input("ğŸ”— æ±‚äººURL 3")
    urls_input_4 = st.text_input("ğŸ”— æ±‚äººURL 4")
    urls_input_5 = st.text_input("ğŸ”— æ±‚äººURL 5")
    submitted = st.form_submit_button("â–¶ï¸ æƒ…å ±ã‚’æŠ½å‡º")

def get_text(label):
    elem = soup.find("th", string=label)
    if elem:
        td = elem.find_next_sibling("td")
        if td:
            return td.get_text(strip=True)
    return ""

def get_div_text_by_attr(name):
    div = soup.find("div", {"class": "m05", "name": name})
    return div.get_text(strip=True) if div else ""

def generate_summary(desc, salary_min, salary_max, loc, time, welfare, holiday, notes, job_title):
    lines = []
    if job_title:
        lines.append(f"ãƒ»è·ç¨®ï¼š{job_title}")
    if desc:
        lines.append(f"ãƒ»ä»•äº‹å†…å®¹ï¼š{desc}")
    if holiday:
        lines.append(f"ãƒ»ä¼‘æ—¥ï¼š{holiday}")
    benefit_keywords = []
    if any(kw in welfare + notes for kw in ["ç¤¾å®…", "ä½å®…æ‰‹å½“", "é€€è·é‡‘"]):
        benefit_keywords.append("å……å®Ÿã—ãŸç¦åˆ©åšç”Ÿ")
    if any(kw in welfare + notes for kw in ["è³‡æ ¼å–å¾—", "ç ”ä¿®", "ã‚­ãƒ£ãƒªã‚¢"]):
        benefit_keywords.append("ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—æ”¯æ´ã‚ã‚Š")
    if any(kw in welfare + notes for kw in ["è‚²å…", "æ‰¶é¤Š", "å­è‚²ã¦"]):
        benefit_keywords.append("è‚²å…æ”¯æ´åˆ¶åº¦ã‚ã‚Š")
    if any(kw in welfare + notes + loc for kw in ["ãƒã‚¤ã‚«ãƒ¼", "è»Šé€šå‹¤", "é§è»Šå ´"]):
        benefit_keywords.append("ãƒã‚¤ã‚«ãƒ¼é€šå‹¤OK")
    if any(kw in welfare + notes for kw in ["é€šå‹¤æ‰‹å½“", "è³‡æ ¼æ‰‹å½“", "å½¹è·æ‰‹å½“", "å‡¦é‡æ”¹å–„æ‰‹å½“", "å¤œå‹¤æ‰‹å½“"]):
        benefit_keywords.append("å„ç¨®æ‰‹å½“ã‚ã‚Š")
    match = re.search(r"å¹´é–“ä¼‘æ—¥\s*(\d{2,3})æ—¥", welfare + notes)
    if match:
        benefit_keywords.append(f"å¹´é–“ä¼‘æ—¥{match.group(1)}æ—¥")
    if benefit_keywords:
        lines.append(f"ãƒ»ç¦åˆ©åšç”Ÿï¼š{'ã€'.join(benefit_keywords)}")
    return "\n".join(lines) if lines else "æ±‚äººæƒ…å ±ã¯ç¾åœ¨æº–å‚™ä¸­ã§ã™ã€‚ãŠæ°—è»½ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"

def extract_recommendations(salary_min, welfare, notes, work_desc, location):
    recs = []
    try:
        if salary_min and int(salary_min) >= 250000:
            recs.append("é«˜çµ¦ä¸ï¼ˆæœˆçµ¦25ä¸‡å††ä»¥ä¸Šï¼‰")
    except ValueError:
        pass
    if "ãƒ¬ã‚¢" in work_desc or "ä¹…ã—ã¶ã‚Š" in work_desc:
        recs.append("å¸Œå°‘ãªãƒ¬ã‚¢æ±‚äºº")
    if any(kw in (welfare + notes) for kw in ["ç¤¾å®…", "è³‡æ ¼", "é€€è·é‡‘", "æ‰¶é¤Š", "ä½å®…"]):
        recs.append("ç¦åˆ©åšç”ŸãŒå……å®Ÿ")
    if any(kw in (work_desc + notes) for kw in ["å¤œå‹¤ãªã—", "æ®‹æ¥­ãªã—", "æ—¥å‹¤ã®ã¿"]):
        recs.append("åƒãã‚„ã™ã„å‹¤å‹™ä½“åˆ¶")
    if any(kw in (welfare + notes + location) for kw in ["é§…", "ãƒã‚¤ã‚«ãƒ¼", "è»Šé€šå‹¤", "ãƒã‚¹"]):
        recs.append("ã‚¢ã‚¯ã‚»ã‚¹è‰¯å¥½")
    fallback = ["ãƒ–ãƒ©ãƒ³ã‚¯OK", "ç ”ä¿®åˆ¶åº¦ã‚ã‚Š", "ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é‡è¦–", "åœ°åŸŸå¯†ç€å‹", "ã‚·ãƒ•ãƒˆæŸ”è»Ÿå¯¾å¿œ"]
    while len(recs) < 3:
        extra = random.choice(fallback)
        if extra not in recs:
            recs.append(extra)
    return recs

if submitted:
    urls = [u.strip() for u in [urls_input_1, urls_input_2, urls_input_3, urls_input_4, urls_input_5] if u]
    if not urls:
        st.warning("URLã‚’1ä»¶ä»¥ä¸Šå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        for i, url in enumerate(urls, 1):
            try:
                response = requests.get(url)
                response.encoding = response.apparent_encoding
                soup = BeautifulSoup(response.text, 'html.parser')

                job_title = get_text("è·ç¨®")
                company = get_text("äº‹æ¥­æ‰€å")
                work_desc = get_text("ä»•äº‹å†…å®¹")
                area = get_div_text_by_attr("szci")
                location = get_text("å°±æ¥­å ´æ‰€")
                employment = get_div_text_by_attr("koyoKeitai") or get_text("é›‡ç”¨å½¢æ…‹")
                salary = soup.find("div", class_="mt05")
                salary = salary.get_text(strip=True) if salary else ""
                salary_type = get_text("è³ƒé‡‘å½¢æ…‹")
                work_time = get_text("å°±æ¥­æ™‚é–“")
                holiday = get_text("ä¼‘æ—¥ç­‰")
                qualification = get_text("å¿…è¦ãªå…è¨±ãƒ»è³‡æ ¼")
                experience = get_text("å¿…è¦ãªçµŒé¨“ç­‰")
                welfare = get_text("åŠ å…¥ä¿é™ºç­‰")
                notes = get_text("å‚™è€ƒ")
                basic_salary = get_text("åŸºæœ¬çµ¦ï¼ˆï½ï¼‰")
                allowance_b = get_text("å®šé¡çš„ã«æ”¯æ‰•ã‚ã‚Œã‚‹æ‰‹å½“ï¼ˆï½‚ï¼‰")
                fixed_overtime = get_text("å›ºå®šæ®‹æ¥­ä»£ï¼ˆï½ƒï¼‰")
                extra_allowance = get_text("ãã®ä»–ã®æ‰‹å½“ç­‰ä»˜è¨˜äº‹é …ï¼ˆï½„ï¼‰")
                work_days = get_text("é€±æ‰€å®šåŠ´åƒæ—¥æ•°")
                car_commute = get_text("ãƒã‚¤ã‚«ãƒ¼é€šå‹¤")

                salary_nums = re.findall(r"\d{3,5}", salary.replace(",", ""))
                salary_min = salary_nums[0] if len(salary_nums) >= 1 else ""
                salary_max = salary_nums[1] if len(salary_nums) >= 2 else salary_min

                job_summary = generate_summary(work_desc, salary_min, salary_max, location, work_time, welfare, holiday, notes, job_title)
                recommendations = extract_recommendations(salary_min, welfare, notes, work_desc, location)
                custom_title = f"{employment}ï½œ{area}ï½œ{job_title}"

                with st.expander(f"ğŸ“„ {custom_title}", expanded=False):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.markdown("### ğŸ—‚ï¸ æ±‚äººæŠ½å‡ºæƒ…å ±")
                        st.markdown(f"""
**äº‹æ¥­æ‰€å**: {company}  
**è·ç¨®**: {job_title}  
**æ‰€åœ¨åœ°**: {location}  
**ä»•äº‹å†…å®¹**: {work_desc}  
**é›‡ç”¨å½¢æ…‹**: {employment}  
**çµ¦ä¸ï¼ˆaï¼‹bï¼‹cï¼‰**: {salary}  
**åŸºæœ¬çµ¦ï¼ˆaï¼‰**: {basic_salary}  
**æ‰‹å½“ï¼ˆbï¼‰**: {allowance_b}  
**å›ºå®šæ®‹æ¥­ä»£ï¼ˆcï¼‰**: {fixed_overtime}  
**ãã®ä»–æ‰‹å½“ç­‰ï¼ˆdï¼‰**: {extra_allowance}  
**ãƒã‚¤ã‚«ãƒ¼é€šå‹¤**: {car_commute}  
**é€±æ‰€å®šåŠ´åƒæ—¥æ•°**: {work_days}  
**ä¼‘æ—¥ç­‰**: {holiday}  
                        """)

                    with col2:
                        st.markdown("### ğŸ“Œ æ±‚äººã‚¿ã‚¤ãƒˆãƒ«")
                        st.markdown(custom_title)

                        st.markdown("### ğŸ¯ ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆ")
                        if recommendations:
                            st.markdown("ã€ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆã€‘ " + " ".join([f"â– {r}" for r in recommendations]))
                        else:
                            st.markdown("ã€ãŠã™ã™ã‚ãƒã‚¤ãƒ³ãƒˆã€‘ è©²å½“æƒ…å ±ãªã—")

                        st.markdown("### âœ¨ æ±‚äººæ¦‚è¦")
                        st.markdown(job_summary)

            except Exception as e:
                st.error(f"æ±‚äºº {i} ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
